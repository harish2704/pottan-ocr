#!/usr/bin/env bash

thisFile=$( readlink -f $0 )
thisDir=$(dirname $thisFile )

export PYTHONPATH+=:$thisDir/../
export PYTHONIOENCODING=utf-8



datagen(){
  # ./gen-glyph-list.js
  python3 -m pottan_ocr.data_gen "$@"
  # ipython3 --matplotlib=tk ./data_gen.py
}


train(){
  python3 -m pottan_ocr.train "$@"
  # ipython3 --matplotlib=tk  -m pottan_ocr.train -- "$@"
}


extractWikiDump(){
  node ./collect-wiki-data.js "$@"
}


ocr(){
  crnnPath="$1"
  imageInput="$2"
  outputPath=${3:-./pottan_ocr_output.html}

  if [[ $1 == '--help' || $1 == '-h' || -z $2 ]];then
  cat<<EOF
Usage: ./pottan ocr <trained_model.h5> <iamge_path> [ pottan_ocr_output.html ]
EOF
  exit 0;
  fi

  baseName=$(basename "$imageInput")
  tmpdir="./tmp/"
  mkdir -p "$tmpdir"

  echo "Executing tesseract ocr for line segmentation ..."
  # -c tessedit_write_images=1  can be used to write binary image
  tesseract -c tessedit_create_hocr=1 "$imageInput"  "$tmpdir/out"

  echo "Running pottan_ocr for text recognition ..."
  python3 -m pottan_ocr.ocr_hocr --crnn "$crnnPath"  --img "$imageInput"  --hocr  "$tmpdir/out.hocr" --output "$outputPath"

  if which xdg-open; then
    xdg-open "$outputPath"
  else
    echo "OCR completed. Open '$outputPath' to see the results"
  fi
}


# For debugging
visualize_line_segmentation(){
  tesseract  -c tessedit_create_tsv=1 "$1" out
  cat out.tsv | awk '{ if( $1==4 ){ print "fill-opacity 0.1 rectangle",$7","$8,$7+$9","$8+$10 } }' > rect.txt
  convert "$1" -stroke red  -draw @rect.txt dbg.png
}


if [ -z $1 ] || [ $1 == '--help' ]; then
  cat<<EOF
Usage:
./pottan <command> [ arguments ]

List of available commands ( See '--help' of individual command for more details ):

    extractWikiDump - Extract words from wiki xml dump ( most most of the text corpus ). Output is written to stdout.

    datagen         - Prepare training data from data/train.txt & data/validate.txt. ( Depreciated. used only for manual varification of training data )

    train           - Run the training

    ocr             - Run charector recognition with a pre-trained model and image file
EOF
else
  cmd=$1
  shift
  $cmd "$@"
fi

